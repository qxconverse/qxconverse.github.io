<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>深度学习中Dropout浅析 | qxconverse</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="关于Dropout这个概念，之前在学习深度学习的那本花书中遇到过，在项目中通过Caffe、Keras也用过，但是没有仔细研究过它是做什么的，而仅仅是拿过来用，最近看了一些相关的博客，想总结一下。 Dropout的作用是为了防止过拟合的，特别是当训练集数据量较小的时候，这就会导致其泛化能力大大下降。而加上Dropout的操作，其作用是让某些神经元失去作用，即在每次训练的时候，每个神经元有一定的几率被">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习中Dropout浅析">
<meta property="og:url" content="http://yoursite.com/2017/03/10/深度学习中Dropout浅析/index.html">
<meta property="og:site_name" content="qxconverse">
<meta property="og:description" content="关于Dropout这个概念，之前在学习深度学习的那本花书中遇到过，在项目中通过Caffe、Keras也用过，但是没有仔细研究过它是做什么的，而仅仅是拿过来用，最近看了一些相关的博客，想总结一下。 Dropout的作用是为了防止过拟合的，特别是当训练集数据量较小的时候，这就会导致其泛化能力大大下降。而加上Dropout的操作，其作用是让某些神经元失去作用，即在每次训练的时候，每个神经元有一定的几率被">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://img.blog.csdn.net/20180310165212885?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXhjb252ZXJzZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:updated_time" content="2018-04-08T05:03:00.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习中Dropout浅析">
<meta name="twitter:description" content="关于Dropout这个概念，之前在学习深度学习的那本花书中遇到过，在项目中通过Caffe、Keras也用过，但是没有仔细研究过它是做什么的，而仅仅是拿过来用，最近看了一些相关的博客，想总结一下。 Dropout的作用是为了防止过拟合的，特别是当训练集数据量较小的时候，这就会导致其泛化能力大大下降。而加上Dropout的操作，其作用是让某些神经元失去作用，即在每次训练的时候，每个神经元有一定的几率被">
<meta name="twitter:image" content="http://img.blog.csdn.net/20180310165212885?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXhjb252ZXJzZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
  
    <link rel="alternate" href="/atom.xml" title="qxconverse" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">qxconverse</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-深度学习中Dropout浅析" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/10/深度学习中Dropout浅析/" class="article-date">
  <time datetime="2017-03-10T09:48:55.000Z" itemprop="datePublished">2017-03-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      深度学习中Dropout浅析
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>关于Dropout这个概念，之前在学习深度学习的那本花书中遇到过，在项目中通过Caffe、Keras也用过，但是没有仔细研究过它是做什么的，而仅仅是拿过来用，最近看了一些相关的博客，想总结一下。</p>
<p>Dropout的作用是为了防止过拟合的，特别是当训练集数据量较小的时候，这就会导致其泛化能力大大下降。而加上Dropout的操作，其作用是让某些神经元失去作用，即在每次训练的时候，每个神经元有一定的几率被移除。</p>
<p>其实，Dropout可以被认为是集成大量深层神经网络的实用Bagging方法。Bagging涉及训练多个模型，并在每个测试样本上评估多个模型。当每个模型都是一个很大的神经网络时，这似乎是不切实际的，因为训练和评估这样的网络需要花费很多运行时间和内存。Dropout提供了一种廉价的Bagging集成近似，能够训练和评估指数级数量的神经网络。</p>
<p>它所做的就是在训练过程中集成包括所有从基础网络除去非输出单元后形成的子网络。简单一点的是乘零操作，即将一些单元的输出乘零就能有效地删除一个单元。而有些框架的实现就是如此。比如keras。</p>
<p><img src="http://img.blog.csdn.net/20180310165212885?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXhjb252ZXJzZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>回想一下Bagging学习，我们定义$k$个不同的模型，从训练集有替换采样构造$k$个不同的数据集，然后在训练集$i$上训练模型$i$。Dropout的目标是在指数级数量的神经网络上近似这个过程。具体来说，在训练中使用Dropout时，我们会使用基于小批量的学习算法和较小的步长，如梯度下降等。我们每次在小批量中加载一个样本，然后随机抽样应用于网络中所有输入和隐藏单元的不同二值掩码。对于每个单元，掩码是独立采样的。掩码值为1 的采样概率（导致包含一个单元）是训练开始前一个固定的超参数。其实这个就是dropout的参数，其取值范围为$[0,1]$.</p>
<p>以下是keras中关于dropout的函数实现，其实它使用随机数生成器生成0，1的向量，然后分别乘上该神经元的值。最后需要注意的是每个值还需要除以（1-level）的概率。其中level即是dropout的参数（以[0,1]之间某个值作为丢弃概率的参数）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">def dropout(x, level, noise_shape=None, seed=None):</span><br><span class="line">    &quot;&quot;&quot;Sets entries in `x` to zero at random,</span><br><span class="line">    while scaling the entire tensor.</span><br><span class="line"></span><br><span class="line">    # Arguments</span><br><span class="line">        x: tensor</span><br><span class="line">        level: fraction of the entries in the tensor</span><br><span class="line">            that will be set to 0.</span><br><span class="line">        noise_shape: shape for randomly generated keep/drop flags,</span><br><span class="line">            must be broadcastable to the shape of `x`</span><br><span class="line">        seed: random seed to ensure determinism.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if level &lt; 0. or level &gt;= 1:</span><br><span class="line">        raise ValueError(&apos;Dropout level must be in interval [0, 1[.&apos;)</span><br><span class="line">    if seed is None:</span><br><span class="line">        seed = np.random.randint(1, 10e6)</span><br><span class="line">    if isinstance(noise_shape, list):</span><br><span class="line">        noise_shape = tuple(noise_shape)</span><br><span class="line"></span><br><span class="line">    rng = RandomStreams(seed=seed)</span><br><span class="line">    retain_prob = 1. - level</span><br><span class="line"></span><br><span class="line">    if noise_shape is None:</span><br><span class="line">        random_tensor = rng.binomial(x.shape, p=retain_prob, dtype=x.dtype)</span><br><span class="line">    else:</span><br><span class="line">        random_tensor = rng.binomial(noise_shape, p=retain_prob, dtype=x.dtype)</span><br><span class="line">        random_tensor = T.patternbroadcast(random_tensor,</span><br><span class="line">                                           [dim == 1 for dim in noise_shape])</span><br><span class="line">    x *= random_tensor</span><br><span class="line">    x /= retain_prob</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>
<p>至于为什么要除以那个值，<a href="http://blog.csdn.net/hjimce/article/details/50413257" target="_blank" rel="noopener">可以查看这篇博客的解释。</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/10/深度学习中Dropout浅析/" data-id="cjov8y3ov000x4uniwvf0atoa" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/07/30/win10+VS2015+CPU-Only安装与配置Caffe/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          win10+VS2015+CPU-Only安装与配置Caffe
        
      </div>
    </a>
  
  
    <a href="/2017/03/02/在python3.5中使用OpenCV/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">在python3.5中使用OpenCV</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CV/">CV</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式系统/">分布式系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构与算法/">数据结构与算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法与数据结构/">算法与数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机基础/">计算机基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/面试/">面试</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/24/设计模式相关/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/11/24/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/04/14/leetcode(1-100)/">leetcode代码(1-100)</a>
          </li>
        
          <li>
            <a href="/2018/04/14/leetcode(101-200)/">leetcode代码(101-200)</a>
          </li>
        
          <li>
            <a href="/2018/04/14/leetcode(201-300)/">leetcode代码(201-300)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 qinxue<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>